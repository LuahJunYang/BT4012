{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from hyperopt import hp \n",
    "from hyperopt import fmin, tpe, Trials \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('Datasets/train_dataset.csv')\n",
    "test_dataset = pd.read_csv('Datasets/test_dataset.csv')\n",
    "\n",
    "PCA_train_dataset = pd.read_csv('Datasets/PCA_train_data.csv')\n",
    "PCA_test_dataset = pd.read_csv('Datasets/PCA_test_data.csv')\n",
    "\n",
    "Tree_train_dataset = pd.read_csv('Datasets/Tree_train_data.csv')\n",
    "Tree_test_dataset = pd.read_csv('Datasets/Tree_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.drop(['is_attack' , 'attack_category' , 'attack'], axis=1)\n",
    "y_train = train_dataset['attack_category']\n",
    "\n",
    "X_test = test_dataset.drop(['is_attack' , 'attack_category' , 'attack'], axis=1)\n",
    "y_test = test_dataset['attack_category']\n",
    "\n",
    "X_pca_train = PCA_train_dataset.drop(columns=['is_attack', 'attack_category',\"attack\"], axis = 1)\n",
    "y_pca_train = PCA_train_dataset[\"attack_category\"]\n",
    "X_pca_test = PCA_test_dataset.drop(columns=['is_attack', 'attack_category',\"attack\"], axis = 1)\n",
    "y_pca_test= PCA_test_dataset[\"attack_category\"]\n",
    "\n",
    "X_tree_train = Tree_train_dataset.drop(columns=['is_attack', 'attack_category',\"attack\"], axis = 1)\n",
    "y_tree_train = Tree_train_dataset[\"attack_category\"]\n",
    "X_tree_test = Tree_test_dataset.drop(columns=['is_attack', 'attack_category',\"attack\"], axis = 1)\n",
    "y_tree_test= Tree_test_dataset[\"attack_category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, y):\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, pred)\n",
    "        precision = precision_score(y_test, pred, average='weighted')\n",
    "        recall = recall_score(y_test, pred, average='weighted') \n",
    "        f1 = f1_score(y_test, pred, average='weighted') \n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # print('{0} Accuracy: {1: .5f} Precision: {2: .5f} Recall: {3: .5f} F1_Score: {4: .5f}'.format(\n",
    "    #     model.__class__.__name__, \n",
    "    #     np.mean(accuracy_scores),\n",
    "    #     np.mean(precision_scores),\n",
    "    #     np.mean(recall_scores),\n",
    "    #     np.mean(f1_scores)))\n",
    "    \n",
    "    return -np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(\"Model: \", model.__class__.__name__)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"####################################\")\n",
    "    \n",
    "    # report = classification_report(y_test, y_pred)\n",
    "    # print(\"Classification Report:\\n\", report)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params(objective_func, search_space):\n",
    "    trials = Trials() \n",
    "\n",
    "    best = fmin(fn=objective_func,\n",
    "                space=search_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=20,\n",
    "                trials=trials,\n",
    "                rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "    print('Best Parameters:', best)\n",
    "    return best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random_states as 42 \n",
    "rs_value = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for XGB, LOGREG, LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params(objective_func, search_space):\n",
    "    trials = Trials() \n",
    "\n",
    "    best = fmin(fn=objective_func,\n",
    "                space=search_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=50,\n",
    "                trials=trials,\n",
    "                rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "    print('Beat Parameters:', best)\n",
    "    return best "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 5/50 [25:09<4:26:31, 355.37s/trial, best loss: -0.9948858870461976]"
     ]
    }
   ],
   "source": [
    "# optimize f1_score\n",
    "xgboost_search_space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 500, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "}\n",
    "\n",
    "def xgboost_objective_func(search_space):\n",
    "    xgboost_clf = xgb.XGBClassifier(\n",
    "        learning_rate=search_space['learning_rate'],\n",
    "        n_estimators=int(search_space['n_estimators']),\n",
    "        max_depth=int(search_space['max_depth']),\n",
    "        min_child_weight=int(search_space['min_child_weight']),\n",
    "        subsample=search_space['subsample'],\n",
    "        colsample_bytree=search_space['colsample_bytree'],\n",
    "        random_state=0\n",
    "    )\n",
    "    \n",
    "    return train_model(xgboost_clf, X_pca_train, y_pca_train)\n",
    "\n",
    "xgboost_best = best_params(xgboost_objective_func, xgboost_search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(random_state = rs_value)\n",
    "\n",
    "xgboost_clf = xgb.XGBClassifier(\n",
    "    learning_rate=xgboost_best['learning_rate'],\n",
    "    n_estimators=int(xgboost_best['n_estimators']),\n",
    "    max_depth=int(xgboost_best['max_depth']),\n",
    "    min_child_weight=int(xgboost_best['min_child_weight']),\n",
    "    subsample=xgboost_best['subsample'],\n",
    "    colsample_bytree=xgboost_best['colsample_bytree'],\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "evaluate(xgboost_clf, X_pca_train, y_pca_train, X_pca_test, y_pca_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "remove_cols = ['Land',\n",
    " 'Root_shell',\n",
    " 'Su_attempted',\n",
    " 'Is_hot_login',\n",
    " 'Is_guest_login',\n",
    " 'Flag_OTH',\n",
    " 'Flag_RSTO',\n",
    " 'Flag_RSTOS0',\n",
    " 'Flag_S1',\n",
    " 'Flag_S2',\n",
    " 'Flag_S3',\n",
    " 'Flag_SH',\n",
    " 'Num_failed_logins_scaled',\n",
    " 'Num_file_creations_scaled',\n",
    " 'Num_access_files_scaled',\n",
    " 'attack_type',\n",
    " 'is_attack',\n",
    " 'attack_category']\n",
    "\n",
    "final_cols_no_pca = [col for col in train_dataset.columns if (col not in remove_cols) and ('PCA' not in col)]\n",
    "\n",
    "final_cols_pca = ['Land', 'Logged_in', 'Root_shell', 'Su_attempted', 'Is_hot_login', 'Is_guest_login', 'Protocol_type_icmp',\n",
    "       'Protocol_type_tcp', 'Protocol_type_udp', 'Flag_OTH', 'Flag_REJ',\n",
    "       'Flag_RSTO', 'Flag_RSTOS0', 'Flag_RSTR', 'Flag_S0', 'Flag_S1',\n",
    "       'Flag_S2', 'Flag_S3', 'Flag_SF', 'Flag_SH', 'Service_encoded'] + [('PCA' + str(i)) for i in range(1,14 + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no_pca = train_dataset[final_cols_no_pca]\n",
    "# attack = 1, normal = 0\n",
    "#y_train_no_pca_is_attack = train_dataset['is_attack']\n",
    "# attack_category 0 (normal),1 (dos),2 (probe),3 (r2l),4 (u2r)\n",
    "y_train_no_pca_attack_cat = train_dataset['attack_category']\n",
    "\n",
    "X_test_no_pca = test_dataset[final_cols_no_pca]\n",
    "# attack = 1, normal = 0\n",
    "#y_test_no_pca_is_attack = test_dataset['is_attack']\n",
    "# attack_category 0 (normal),1 (dos),2 (probe),3 (r2l),4 (u2r)\n",
    "y_test_no_pca_attack_cat = test_dataset['attack_category']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB CLASSIFIER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WITH PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", num_class=len(set(y_train_pca_attack_cat)))\n",
    "xgb_model.fit(X_train_pca, y_train_pca_attack_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_pca_attack_cat, y_pred)\n",
    "precision = precision_score(y_test_pca_attack_cat, y_pred, average='weighted')\n",
    "recall = recall_score(y_test_pca_attack_cat, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test_pca_attack_cat, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
    "print(\"F1 Score: {:.2f}%\".format(f1 * 100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WITHOUT PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, y):\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, pred)\n",
    "        precision = precision_score(y_test, pred, average='weighted')\n",
    "        recall = recall_score(y_test, pred, average='weighted') \n",
    "        f1 = f1_score(y_test, pred, average='weighted') \n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    print('{0} Accuracy: {1: .5f} Precision: {2: .5f} Recall: {3: .5f} F1_Score: {4: .5f}'.format(\n",
    "        model.__class__.__name__, \n",
    "        np.mean(accuracy_scores),\n",
    "        np.mean(precision_scores),\n",
    "        np.mean(recall_scores),\n",
    "        np.mean(f1_scores)))\n",
    "    \n",
    "    return -np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp \n",
    "from hyperopt import fmin, tpe, Trials, STATUS_OK\n",
    "\n",
    "# optimize f1_score\n",
    "xgboost_search_space = {'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 180,\n",
    "        'seed': 0\n",
    "    }\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in skf.split(X_train_no_pca, y_train_no_pca_attack_cat):\n",
    "    X_train, y_train = X_train_no_pca.iloc[train_index], y_train_no_pca_attack_cat.iloc[train_index]\n",
    "    X_test, y_test = X_train_no_pca.iloc[test_index], y_train_no_pca_attack_cat.iloc[test_index]\n",
    "\n",
    "def objective(space):\n",
    "    clf=xgb.XGBClassifier(\n",
    "                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree=int(space['colsample_bytree']))\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"auc\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = xgboost_search_space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_classifier = xgb.XGBClassifier(\n",
    "    colsample_bytree=best_hyperparams['colsample_bytree'],\n",
    "    gamma=best_hyperparams['gamma'],\n",
    "    max_depth= int(best_hyperparams['max_depth']),\n",
    "    min_child_weight=best_hyperparams['min_child_weight'],\n",
    "    reg_alpha=best_hyperparams['reg_alpha'],\n",
    "    reg_lambda=best_hyperparams['reg_lambda']\n",
    ")\n",
    "\n",
    "optimal_classifier.fit(X_train_no_pca, y_train_no_pca_attack_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = optimal_classifier.predict(X_test_no_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_no_pca_attack_cat, y_pred)\n",
    "precision = precision_score(y_test_no_pca_attack_cat, y_pred, average='weighted')\n",
    "recall = recall_score(y_test_no_pca_attack_cat, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test_no_pca_attack_cat, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
    "print(\"F1 Score: {:.2f}%\".format(f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", num_class=len(set(y_train_no_pca_attack_cat)))\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "estimators = [('xgb', xgb_model), ('rf', rf_model)]\n",
    "stacking_model = StackingClassifier(estimators=estimators, final_estimator=xgb.XGBClassifier(objective=\"multi:softprob\", num_class=len(set(y_train_pca_attack_cat))))\n",
    "                                     \n",
    "# Split your data into training and validation sets for stacking\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_no_pca, y_train_no_pca_attack_cat, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the stacking model on the training data\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "stacking_pred = stacking_model.predict(X_val)\n",
    "\n",
    "# Evaluate the stacking model\n",
    "accuracy = accuracy_score(y_val, stacking_pred)\n",
    "print(\"Stacking Model Accuracy on Validation Data: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Train the stacking model on the full training data\n",
    "stacking_model.fit(X_train_no_pca, y_train_no_pca_attack_cat)\n",
    "\n",
    "# Make predictions on the test data\n",
    "stacking_test_pred = stacking_model.predict(X_test_no_pca)\n",
    "\n",
    "# Evaluate the stacking model on the test data\n",
    "test_accuracy = accuracy_score(y_test_no_pca_attack_cat, stacking_test_pred)\n",
    "\n",
    "print(\"Stacking Model Accuracy on Test Data: {:.2f}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_no_pca_attack_cat, stacking_test_pred)\n",
    "precision = precision_score(y_test_no_pca_attack_cat, stacking_test_pred, average='weighted')\n",
    "recall = recall_score(y_test_no_pca_attack_cat, stacking_test_pred, average='weighted')\n",
    "f1 = f1_score(y_test_no_pca_attack_cat, stacking_test_pred, average='weighted')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION with L1 L2 REGULARIZATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WITH PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, multi_class='multinomial', max_iter=1000)\n",
    "lr.fit(X_train_pca, y_train_pca_attack_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_pca_attack_cat, y_pred)\n",
    "precision = precision_score(y_test_pca_attack_cat, y_pred, average='weighted')\n",
    "recall = recall_score(y_test_pca_attack_cat, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test_pca_attack_cat, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
    "print(\"F1 Score: {:.2f}%\".format(f1 * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WITHOUT PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],  # Regularization type (L1 or L2)\n",
    "    'C': [0.001, 0.01, 0.1, 1.0, 10, 100],  # Inverse of regularization strength\n",
    "    'solver': ['liblinear', 'lbfgs'],  # Optimization algorithm\n",
    "    'max_iter': [100, 200, 300]  # Maximum number of iterations for convergence\n",
    "}\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(logistic_regression, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_pca, y_train_pca_attack_cat)\n",
    "#Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=best_params['C'], max_iter=best_params['max_iter'], penalty=best_params['penalty'], solver=best_params['solver'])\n",
    "lr.fit(X_train_no_pca, y_train_no_pca_attack_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, multi_class='multinomial', max_iter=1000)\n",
    "#lr.fit(X_train_no_pca, y_train_no_pca_attack_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test_no_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_no_pca_attack_cat, y_pred)\n",
    "precision = precision_score(y_test_no_pca_attack_cat, y_pred, average='weighted')\n",
    "recall = recall_score(y_test_no_pca_attack_cat, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test_no_pca_attack_cat, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
    "print(\"F1 Score: {:.2f}%\".format(f1 * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIGHT GBM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WITH PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train_pca, label=y_train_pca_attack_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(set(y_train_pca_attack_cat)),\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(params, train_data, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_model.predict(X_test_pca, num_iteration=lgb_model.best_iteration).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_pca_attack_cat, y_pred)\n",
    "precision = precision_score(y_test_pca_attack_cat, y_pred, average='weighted')\n",
    "recall = recall_score(y_test_pca_attack_cat, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test_pca_attack_cat, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
    "print(\"F1 Score: {:.2f}%\".format(f1 * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WITHOUT PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize f1_score\n",
    "SEARCH_PARAMS = {'learning_rate': 0.4,\n",
    "                 'max_depth': 15,\n",
    "                 'num_leaves': 20,\n",
    "                 'feature_fraction': 0.8,\n",
    "                 'subsample': 0.2}\n",
    "\n",
    "FIXED_PARAMS={'objective': 'binary',\n",
    "              'metric': 'auc',\n",
    "              'is_unbalance':True,\n",
    "              'boosting':'gbdt',\n",
    "              'num_boost_round':300,\n",
    "              'early_stopping_rounds':30}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in skf.split(X_train_no_pca, y_train_no_pca_attack_cat):\n",
    "    X_train, y_train = X_train_no_pca.iloc[train_index], y_train_no_pca_attack_cat.iloc[train_index]\n",
    "    X_test, y_test = X_train_no_pca.iloc[test_index], y_train_no_pca_attack_cat.iloc[test_index]\n",
    "\n",
    "def objective(space):\n",
    "    clf=lgb.train()\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"auc\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = xgboost_search_space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train_no_pca, label=y_train_no_pca_attack_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(set(y_train_no_pca_attack_cat)),\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(params, train_data, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_model.predict(X_test_no_pca, num_iteration=lgb_model.best_iteration).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_pca_attack_cat, y_pred)\n",
    "precision = precision_score(y_test_pca_attack_cat, y_pred, average='weighted')\n",
    "recall = recall_score(y_test_pca_attack_cat, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test_pca_attack_cat, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
    "print(\"F1 Score: {:.2f}%\".format(f1 * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
